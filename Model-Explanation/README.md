# A Rose by Any Other Name: LLM-Generated Explanations Are Good Proxies for Human Explanations to Collect Label Distributions on NLI

[[paper](https://arxiv.org/abs/2412.13942)]

This repository contains the LLM-generated explanations from Llama3, GTP-4o and Mixtral. We also include human-validated explanations from 100 NLI instances.

## Overall Structure
![Image text](https://github.com/mainlp/MJD-Estimator/blob/main/Model-Explanation/model-explanation-question.png)

## Model Explanations

Each folder contains the original explanation files generated by the LLM and the combined explanation files used in the paper's main experiment.

Human explanations are from the VariErr NLI dataset ([paper](https://aclanthology.org/2024.acl-long.123.pdf), [data](https://github.com/mainlp/VariErr-NLI)).

We also include the human-validated explanations (from Llama3) in [file](https://github.com/mainlp/MJD-Estimator/blob/main/Model-Explanation/Validated_Llama3_Explanations.xlsx).

We adopt the [MJD-Estimator](https://github.com/mainlp/MJD-Estimator) to generate and evaluate model judgment distributions.

## Citation
If you use the data, please cite the paper below:

[A Rose by Any Other Name: LLM-Generated Explanations Are Good Proxies for Human Explanations to Collect Label Distributions on NLI](https://arxiv.org/abs/2412.13942)



```


```
