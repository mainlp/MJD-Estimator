{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.special import rel_entr\n",
    "import os\n",
    "\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import math\n",
    "from scipy.stats import entropy, wasserstein_distance\n",
    "from scipy.spatial.distance import correlation\n",
    "import dcor\n",
    "from dcor import distance_correlation\n",
    "\n",
    "os.chdir(os.getenv(\"WORKING_DIR\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: transform all raw data into distribution files as \"train.son\"\n",
    "# arguments\n",
    "ChaosNLI_file = 'NLI_explanations.json'\n",
    "# extract premise and hypothesis\n",
    "Raw_input = ''\n",
    "# where you save the raw data from MJD-generator.ipynb\n",
    "Raw_output = ''\n",
    "# where you would like to save the distribution files\n",
    "\n",
    "sfmax_temperature = 20\n",
    "# temparature cofficient for softmax transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all data\n",
    "\n",
    "with open(ChaosNLI_file) as f:\n",
    "    lines = f.readlines()\n",
    "    data = [json.loads(line) for line in lines]\n",
    "    chaos_df = pd.DataFrame(data)\n",
    "    \n",
    "chaos_df_cols = chaos_df[['premise','hypothesis']]\n",
    "\n",
    "\n",
    "# loop through the json files in the folder \"/data_raw\" read \n",
    "file_dict = {}\n",
    "for filename in os.listdir(Raw_input):\n",
    "    with open(f'{Raw_input}/{filename}') as f:\n",
    "        lines = f.readlines()\n",
    "        data = [json.loads(line) for line in lines]\n",
    "        df = pd.DataFrame(data)\n",
    "        df = pd.concat([df, chaos_df_cols], axis=1)\n",
    "        file_dict[filename] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the distribution files for distribution comparison and fine-tuning comparison\n",
    "\n",
    "def normalize(instance):\n",
    "    instance = np.array(instance)\n",
    "    instance_norm = instance / np.sum(instance, axis=2)[:, :, np.newaxis]\n",
    "    return instance_norm\n",
    "\n",
    "def softmax(instance, temperature=sfmax_temperature):\n",
    "    instance = np.array(instance)\n",
    "    instance_norm = np.exp(instance/temperature) / np.sum(np.exp(instance/temperature), axis=2)[:, :, np.newaxis]\n",
    "    return instance_norm\n",
    "\n",
    "\n",
    "# save distribution from normalization transformation\n",
    "for number in ['zero', 'one', 'two', 'three', 'four']:\n",
    "    for mode in ['without_label', 'with_label']:\n",
    "        df = file_dict[f'Llama3_{mode}.json']\n",
    "        if number == 'zero':\n",
    "            # add one dimention to the second axis\n",
    "            df[f'scores adding {number}'] = df[f'scores adding {number}'].apply(lambda x: np.expand_dims(x, axis=1))\n",
    "            \n",
    "        df[f'scores adding {number} norm probs'] = df[f'scores adding {number}'].apply(lambda x: normalize(x))\n",
    "        df[f'scores adding {number} norm probs avg'] = df[f'scores adding {number} norm probs'].apply(lambda x: np.mean(x, axis=(0,1)))\n",
    "        # only keep the column \"premise\", \"hypothesis\", \"scores adding one with labels norm probs avg\"\n",
    "        df_process = df[[\"premise\", \"hypothesis\", f\"scores adding {number} norm probs avg\"]]\n",
    "        # change the name of the column \"scores adding one with labels norm probs avg\" to \"label\"\n",
    "        df_process = df_process.rename(columns={f\"scores adding {number} norm probs avg\": \"label\"})\n",
    "        # create folder if not exist\n",
    "        os.makedirs(f\"{Raw_output}/train/{mode}/add_{number}/\", exist_ok=True)\n",
    "        # save to folder \"Raw_output/\" as json\n",
    "        df_process.to_json(f\"{Raw_output}/train/{mode}/add_{number}/train.json\", orient=\"records\", lines=True)\n",
    "\n",
    "\n",
    "# save distribution from softmax transformation\n",
    "for number in ['zero', 'one', 'two', 'three', 'four']:\n",
    "    for mode in ['without_label', 'with_label']:\n",
    "        df = file_dict[f'Llama3_{mode}.json']\n",
    "        if number == 'zero':\n",
    "            # add one dimention to the second axis\n",
    "            df[f'scores adding {number}'] = df[f'scores adding {number}'].apply(lambda x: np.expand_dims(x, axis=1))\n",
    "            \n",
    "        df[f'scores adding {number} softmax probs'] = df[f'scores adding {number}'].apply(lambda x: softmax(x))\n",
    "        df[f'scores adding {number} softmax probs avg'] = df[f'scores adding {number} softmax probs'].apply(lambda x: np.mean(x, axis=(0,1)))\n",
    "        # only keep the column \"premise\", \"hypothesis\", \"scores adding one with labels norm probs avg\"\n",
    "        df_process = df[[\"premise\", \"hypothesis\", f\"scores adding {number} softmax probs avg\"]]\n",
    "        # change the name of the column \"scores adding one with labels norm probs avg\" to \"label\"\n",
    "        df_process = df_process.rename(columns={f\"scores adding {number} softmax probs avg\": \"label\"})\n",
    "        # create folder if not exist\n",
    "        os.makedirs(f\"{Raw_output}/train_softmax/T_{sfmax_temperature}/{mode}/add_{number}/\", exist_ok=True)\n",
    "        # save to folder \"data/llm-translate/add_one_label_train_chaos_dev/\" as json\n",
    "        df_process.to_json(f\"{Raw_output}/train_softmax/T_{sfmax_temperature}/{mode}/add_{number}/train.json\", orient=\"records\", lines=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: calculate the metrics in distribution comparison\n",
    "# all calculation methods\n",
    "\n",
    "def kl_divergence(P, Q, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Calculate the Kullback-Leibler divergence between two probability distributions.\n",
    "\n",
    "    Parameters:\n",
    "    P (array-like): The first probability distribution.\n",
    "    Q (array-like): The second probability distribution.\n",
    "    epsilon (float): A small value to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "    float: The KL divergence value.\n",
    "    \"\"\"\n",
    "    # Convert P and Q to numpy arrays\n",
    "    P = np.asarray(P, dtype=np.float64)\n",
    "    Q = np.asarray(Q, dtype=np.float64)\n",
    "    \n",
    "    # Add epsilon to avoid zero probabilities\n",
    "    P = np.clip(P, epsilon, 1)\n",
    "    Q = np.clip(Q, epsilon, 1)\n",
    "    \n",
    "    # Normalize the distributions to ensure they sum to 1\n",
    "    P = P / np.sum(P)\n",
    "    Q = Q / np.sum(Q)\n",
    "    \n",
    "    # Calculate KL divergence\n",
    "    kl_divergence_value = np.sum(rel_entr(P, Q))\n",
    "    \n",
    "    return kl_divergence_value\n",
    "\n",
    "\n",
    "def jensen_shannon(p, q):\n",
    "    # calculate JSD\n",
    "    p = np.asarray(p, dtype=np.float64)\n",
    "    q = np.asarray(q, dtype=np.float64)\n",
    "    m = (p + q) / 2\n",
    "    return math.sqrt((kl_divergence(p, m) + kl_divergence(q, m)) / 2)\n",
    "\n",
    "\n",
    "def tvd(model_probs, human_probs):\n",
    "    \"\"\"\n",
    "    Computes TVD scores allowing for multiple sub-samples and groups (=classifiers).\n",
    "\n",
    "    p: classifiers [G, 1, N, C]\n",
    "    q: MLE given (sub-samples of) annotations [1, S, N, C]\n",
    "\n",
    "    returns:\n",
    "        tvd: [G, S, N] (mean_per=None), [G, S] (mean_per=sample), [G, N] (mean_per=instance)\n",
    "    \"\"\"\n",
    "    model_probs = np.array(model_probs)\n",
    "    human_probs = np.array(human_probs)\n",
    "    assert model_probs.max() <= 1.0 and model_probs.min() >= 0\n",
    "    assert human_probs.max() <= 1.0 and human_probs.min() >= 0\n",
    "\n",
    "    tvds = np.sum(np.abs(model_probs - human_probs), axis=-1) / 2\n",
    "    return tvds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate metrics\n",
    "\n",
    "def get_metric_in_Dist(Chaos_dir, target_dir,if_uni=0):\n",
    "    Chaos_file = os.path.join(Chaos_dir,'train.json')\n",
    "    target_file = os.path.join(target_dir,'train.json')\n",
    "    result_list = []\n",
    "    metrics = ['kl_divergence','jensenshannon','tvd']\n",
    "\n",
    "    with open(Chaos_file) as f:\n",
    "        lines = f.readlines()\n",
    "        data = [json.loads(line) for line in lines]\n",
    "        record_df = pd.DataFrame(data)\n",
    "    with open(target_file) as f:\n",
    "        lines = f.readlines()\n",
    "        data = [json.loads(line) for line in lines]\n",
    "        target_df = pd.DataFrame(data)\n",
    "    \n",
    "    if if_uni:\n",
    "        # if you want the uniform-distribution retsults\n",
    "        record_df['target'] = record_df['label'].apply(lambda x: [1/3,1/3,1/3])\n",
    "    else:\n",
    "        record_df['target'] = target_df['label']\n",
    "    \n",
    "    for metric in metrics:\n",
    "        record_df['target metric'] = record_df.apply(lambda x: eval(metric)(x['label'], x[f'target']), axis=1)\n",
    "        result_list.append(float(format(record_df['target metric'].mean(),'.5f')))\n",
    "    result_list.append(float(format(distance_correlation(np.vstack(record_df[f'label'].to_list()),np.vstack(record_df['target'].to_list())),'.5f')))\n",
    "\n",
    "    return result_list\n",
    "\n",
    "\n",
    "# get fine-tuning results, after conduct fine-tuning by MJD-fine-tuning\n",
    "\n",
    "# def get_ft_results(inputdir):\n",
    "#     ft_result_list = []\n",
    "#     for model in ['bert','roberta']:\n",
    "#         for type in ['eval_results.json','test_var_results.json']:\n",
    "#             result_file = os.path.join(\"output/\",f\"{model}/{inputdir}/{type}\")\n",
    "#             with open(result_file) as f:\n",
    "#                 eval_results = json.load(f)\n",
    "#             for metric in ['eval_kl_divergence','eval_loss','eval_weighted_F1']:\n",
    "#                 ft_result_list.append(float(format(eval_results[metric],'.5f')))\n",
    "#     return ft_result_list\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save comparison results to excel\n",
    "\n",
    "import openpyxl\n",
    "\n",
    "data = []\n",
    "\n",
    "ChaosNLI_file_341 = ''\n",
    "MNLIonehot_dir = ''\n",
    "MNLI_distribution_dir = ''\n",
    "VariErr_distribution_dir = ''\n",
    "# All file as {'premise':...,'hypothesis':...,'label':[probE, probN, probC]}\n",
    "\n",
    "\n",
    "# baseline\n",
    "for filename in [ChaosNLI_file, MNLIonehot_dir, MNLI_distribution_dir, VariErr_distribution_dir]:\n",
    "    data.append(get_metric_in_Dist(ChaosNLI_file_341, filename))\n",
    "\n",
    "\n",
    "# Llama origin\n",
    "# Llama_origin = \".../add_zero/\"\n",
    "# Llama_origin_sf = \"/train_softmax/T_20/.../add_zero/\"\n",
    "# for filename in [Llama_origin, Llama_origin_sf]:\n",
    "#     data.append(get_metric_in_Dist(ChaosNLI_file_341, filename))\n",
    "\n",
    "\n",
    "# Llama with VariErr\n",
    "# .../add_{how_many}/train.json\n",
    "\n",
    "# for [ifnorm, ifwith] in [['train','Llama3-without-label'],['train','Llama3-with-label'],['train_softmax/T_20','Llama3-without-label'],['train_softmax/T_20','Llama3-with-label']]:\n",
    "#     for howmany in ['add_four','add_three','add_two','add_one']:\n",
    "#         filename = f\".../Llama3/{ifwith}/{ifnorm}/Llama/{howmany}/\"\n",
    "#         data.append(get_metric_in_Dist(ChaosNLI_file_341, filename))\n",
    "\n",
    "\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "ws = wb.active\n",
    "\n",
    "\n",
    "x = 4  \n",
    "# for every 4 line, calculate the average score\n",
    "row_offset = 0  \n",
    "for i in range(0, len(data), x):\n",
    "    for j in range(x):\n",
    "        if i + j < len(data):\n",
    "            for k, value in enumerate(data[i + j]):\n",
    "                ws.cell(row=i + j + 1 + row_offset, column=k + 1, value=value)\n",
    "    if i + x - 1 < len(data):  \n",
    "        avg_row = []\n",
    "        for col in range(len(data[0])):\n",
    "            avg_value = sum(data[i + r][col] for r in range(x)) / x\n",
    "            avg_row.append(avg_value)\n",
    "        for k, value in enumerate(avg_row):\n",
    "            ws.cell(row=i + x + 1 + row_offset, column=k + 1, value=value)\n",
    "        row_offset += 1\n",
    "\n",
    "# save as Excel\n",
    "wb.save(\"output.xlsx\")\n",
    "print(\"Data written to output.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3: ternary visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ternary\n",
    "import numpy as np\n",
    "\n",
    "# Llama\n",
    "datasets = []\n",
    "# read the distributions as you want,like Llama3, Llama3 with explanations, Llama3 with explicit explanations\n",
    "\n",
    "data_name = ['Llama3','+ EXs','+ explicit EXs']\n",
    "colors = ['k', 'orange', 'purple']\n",
    "markers = [ 'D', 'v', '<']\n",
    "\n",
    "distributions = [data_sets[i].apply(lambda x: [x[0]*100,x[1]*100,x[2]*100]).tolist() for i in range(len(data_sets))]\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i, data in enumerate(distributions):\n",
    "    scale = max(max(point) for point in data)\n",
    "    def scale_center(data, scale_factor):\n",
    "        centered_data = (data - np.mean(data, axis=0)) * scale_factor + np.mean(data, axis=0)\n",
    "        return centered_data\n",
    "\n",
    "    # scale cofficient\n",
    "    scale_factor = 3.3\n",
    "    scaled_data = scale_center(data, scale_factor)\n",
    "    # if you want to scale up\n",
    "    # if i==1:\n",
    "    #     data = scaled_data\n",
    "    ax = axs[i]\n",
    "    figure, tax = ternary.figure(ax=ax, scale=100)\n",
    "    tax.boundary(linewidth=2.0)\n",
    "    tax.gridlines(multiple=10, color=\"grey\")\n",
    "    # tax.gridlines(multiple=0.1, color=\"gray\", linestyle='-', linewidth=0.5)\n",
    "    # if i == 1:\n",
    "    #     tax.scatter(scaled_data, marker=markers[i], color=colors[i], label=data_name[i])\n",
    "    # else:\n",
    "    #     tax.scatter(data, marker=markers[i], color=colors[i], label=data_name[i])\n",
    "    tax.scatter(data, marker=markers[i], color=colors[i], label=data_name[i])\n",
    "    tax.ticks(axis='lbr', linewidth=1, multiple=10)\n",
    "    # tax.ticks(axis='lbr', linewidth=1, multiple=0.1, ticks=[0.1 * i for i in range(1, 10)] + [1.0])\n",
    "    # ticks = [0.1 * j for j in range(1, 10)] + [1.0]\n",
    "    # tax.ticks(ticks=ticks, axis='lbr', linewidth=1, clockwise=False, offset=0.02)\n",
    "    \n",
    "    tax.clear_matplotlib_ticks()\n",
    "    tax.get_axes().axis('off')\n",
    "    # tax.get_axes().tick_params(axis='both', which='major', labelsize=30)\n",
    "    tax.left_axis_label(\"← Entailment\",fontsize=32, offset=0.16)\n",
    "    tax.right_axis_label(\"← Neutral\",fontsize=32, offset=0.16)\n",
    "    tax.bottom_axis_label(\"Contradiction →\",fontsize=32, offset=0.04)\n",
    "    # tax.set_title(data_name[i])\n",
    "    tax.legend(fontsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('triangle_k.pdf', format='pdf')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
