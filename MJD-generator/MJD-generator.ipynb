{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import json\n",
    "from itertools import permutations\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augments\n",
    "GPU_DEVICES = '0,1'\n",
    "# GPU used. At least 2 80G A100 for loading Llama3 70B\n",
    "CACHE_DIR = 'models/'\n",
    "# where you save the Llama3 model\n",
    "MODEL_NAME = \"meta-llama/Meta-Llama-3-70B-Instruct\"\n",
    "\n",
    "batch_size = 20\n",
    "# batchz_size while LLM inference\n",
    "input_file = \"NLI_explanations.json\"\n",
    "# pre-processed file as {'premise': ... , 'hypothesis': ..., ..., 'comments': [[explanation, label],...]}\n",
    "if_explicit = 0\n",
    "# if use explicit explanation (add label with explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU_DEVICES\n",
    "\n",
    "model_path = os.path.join(CACHE_DIR,\"model\",MODEL_NAME)\n",
    "tokenizer_path = os.path.join(CACHE_DIR,\"tokenizer\",MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, cache_dir=model_path, torch_dtype=torch.bfloat16,device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=tokenizer_path, padding_side=\"left\")\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_proprocess\n",
    "\n",
    "def permutation1(li=[1,2,3], n=None):\n",
    "    if n and n<= len(li):\n",
    "        return permutations(li, n)\n",
    "    if not n:\n",
    "        return permutations(li)\n",
    "\n",
    "\n",
    "filtf = codecs.open(input_file, 'r', 'utf-8')\n",
    "filts = filtf.readlines()\n",
    "filter_instance = []\n",
    "for line in filts:\n",
    "    data = json.loads(line)\n",
    "    one_instance = []\n",
    "    for key,value in data.items():\n",
    "        one_instance.append(value)\n",
    "    filter_instance.append(one_instance)\n",
    "filtf.close()\n",
    "\n",
    "# divide into batches\n",
    "data_forward = []\n",
    "for i in range(0,len(filter_instance),batch_size):\n",
    "    data_forward.append(filter_instance[i:i+batch_size])\n",
    "\n",
    "option_list = [\"Entailment\",\"Neutral\",\"Contradiction\"]\n",
    "option_dict = {\n",
    "    \"e\": \"Entailment\",\n",
    "    \"n\": \"Neutral\",\n",
    "    \"c\": \"Contradiction\",\n",
    "}\n",
    "\n",
    "option_order_list = [[['Entailment', 'Neutral', 'Contradiction'],[32, 33, 34]], [['Entailment', 'Contradiction', 'Neutral'],[32, 34, 33]], [['Neutral', 'Entailment', 'Contradiction'],[33, 32, 34]], [['Neutral', 'Contradiction', 'Entailment'],[34, 32, 33]], [['Contradiction', 'Entailment', 'Neutral'],[33, 34, 32]], [['Contradiction', 'Neutral', 'Entailment'],[34, 33, 32]]]\n",
    "# [32,33,34] are token ids of /nA, /nB, /nC for Llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module\n",
    "\n",
    "def output_scores(messages, option_order=[32,33,34], model=model, tokenizer=tokenizer):\n",
    "    encodings = []\n",
    "    for batch_one in messages:\n",
    "        encodings.append(tokenizer.apply_chat_template(batch_one, tokenize=False, add_generation_prompt=True))\n",
    "    model_inputs = tokenizer(encodings, return_tensors=\"pt\",add_special_tokens= False, padding=True).to(\"cuda\")\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=256,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        output_logits=True,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=False,\n",
    "    )\n",
    "    ABCscores = []\n",
    "    for i in range(len(messages)):\n",
    "        ABCscores.append([generated_ids.scores[0][i][option_order[0]].tolist(), generated_ids.scores[0][i][option_order[1]].tolist(), generated_ids.scores[0][i][option_order[2]].tolist()])\n",
    "    return ABCscores\n",
    "\n",
    "def message_generate(batch_instance, option_order_word=[\"Entailment\",\"Neutral\",\"Contradiction\"]):\n",
    "    batch_message = []\n",
    "    for one_instance in batch_instance:\n",
    "        promise = one_instance[0]\n",
    "        hypothesis = one_instance[1]\n",
    "        messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"Please determine whether the following statement is true (entailment), undetermined (neutral), or false (contradiction) given the context below and select ONE of the listed options and start your answer with a single letter. \\nContext: {promise} \\nStatement: {hypothesis} \\nA. {option_order_word[0]} \\nB. {option_order_word[1]} \\nC. {option_order_word[2]}. \\nAnswer:\"}\n",
    "        ]\n",
    "        batch_message.append(messages)\n",
    "    return batch_message\n",
    "\n",
    "\n",
    "def message_generate_for_comments(batch_instance, option_order_word=[\"Entailment\",\"Neutral\",\"Contradiction\"], ordered_comments_id=[]):\n",
    "    batch_message = []\n",
    "    for one_instance in batch_instance:\n",
    "        promise = one_instance[0]\n",
    "        hypothesis = one_instance[1]\n",
    "        \n",
    "        comments = \"\"\n",
    "        for i,comments_id in enumerate(ordered_comments_id):\n",
    "            the_comments = one_instance[-1][comments_id][0]\n",
    "            comments +=  f\"\\nComment {i+1}: {the_comments} \"\n",
    "        messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"Please carefully and fairly base your selection on the comments below to determine whether the following statement is true (entailment), undetermined (neutral), or false (contradiction) given the context below and select ONE of the listed options and start your answer with a single letter. \\nContext: {promise} \\nStatement: {hypothesis} {comments}\\nA. {option_order_word[0]} \\nB. {option_order_word[1]} \\nC. {option_order_word[2]}. \\nAnswer:\"}\n",
    "        ]\n",
    "        batch_message.append(messages)\n",
    "    return batch_message\n",
    "\n",
    "\n",
    "def message_generate_for_comments_add_labels(batch_instance, option_order_word=[\"Entailment\",\"Neutral\",\"Contradiction\"], ordered_comments_id=[]):\n",
    "    batch_message = []\n",
    "    for one_instance in batch_instance:\n",
    "        promise = one_instance[0]\n",
    "        hypothesis = one_instance[1]\n",
    "        \n",
    "        comments = \"\"\n",
    "        for i,comments_id in enumerate(ordered_comments_id):\n",
    "            the_comments = one_instance[-1][comments_id][0]\n",
    "            the_comments_label = one_instance[-1][comments_id][1]\n",
    "            comments +=  f\"\\nComment {i+1}: {the_comments} So I choose {option_dict[the_comments_label]}. \"\n",
    "        messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"Please carefully and fairly base your selection on the comments below to determine whether the following statement is true (entailment), undetermined (neutral), or false (contradiction) given the context below and select ONE of the listed options and start your answer with a single letter. \\nContext: {promise} \\nStatement: {hypothesis} {comments}\\nA. {option_order_word[0]} \\nB. {option_order_word[1]} \\nC. {option_order_word[2]}. \\nAnswer:\"}\n",
    "        ]\n",
    "        batch_message.append(messages)\n",
    "    return batch_message\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting MJDs\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "final_results = {}\n",
    "# [0,4,12,24,24]\n",
    "for comments_number in range(5):\n",
    "    print(f\"start process {comments_number}\")\n",
    "    final_results[f\"comments_number_{comments_number}\"] = {}\n",
    "    if comments_number == 0:\n",
    "        for i,one_option_order in tqdm(enumerate(option_order_list)):\n",
    "            final_results[f\"comments_number_{comments_number}\"][f\"option_id_{i}\"] = {}\n",
    "            label_option_list = one_option_order[0]\n",
    "            letter_option_list = one_option_order[1]\n",
    "            all_instance_result = []\n",
    "            for batch_instances in data_forward:\n",
    "                messages = message_generate(batch_instances, option_order_word=label_option_list)\n",
    "                ABCscores = output_scores(messages, option_order=letter_option_list)\n",
    "                all_instance_result += ABCscores\n",
    "            final_results[f\"comments_number_{comments_number}\"][f\"option_id_{i}\"] = all_instance_result\n",
    "    else:\n",
    "        for i,one_option_order in tqdm(enumerate(option_order_list)):\n",
    "            final_results[f\"comments_number_{comments_number}\"][f\"option_id_{i}\"] = {}\n",
    "            label_option_list = one_option_order[0]\n",
    "            letter_option_list = one_option_order[1]\n",
    "            for j,ordered_comments_id in enumerate(list(permutation1(list(range(4)), comments_number))):\n",
    "                final_results[f\"comments_number_{comments_number}\"][f\"option_id_{i}\"][f\"comments_order_{j}\"] = {}\n",
    "                all_instance_result = []\n",
    "                for batch_instances in data_forward:\n",
    "                    if if_explicit :\n",
    "                        messages = message_generate_for_comments_add_labels(batch_instances, option_order_word=label_option_list, ordered_comments_id=list(ordered_comments_id))\n",
    "                    else:\n",
    "                        messages = message_generate_for_comments(batch_instances, option_order_word=label_option_list, ordered_comments_id=list(ordered_comments_id))\n",
    "                    ABCscores = output_scores(messages, option_order=letter_option_list)\n",
    "                    all_instance_result += ABCscores\n",
    "                final_results[f\"comments_number_{comments_number}\"][f\"option_id_{i}\"][f\"comments_order_{j}\"] = all_instance_result\n",
    "\n",
    "realldayufour = []\n",
    "socres_x = {}\n",
    "for instance_id in range(len(filter_instance)):\n",
    "    scores_0 = [] # 6*3\n",
    "    scores_1 = [] # 6*4*3\n",
    "    scores_2 = [] # 6*12*3\n",
    "    scores_3 = [] # 6*24*3\n",
    "    scores_4 = [] # 6*26*3\n",
    "    for i in range(len(option_order_list)):\n",
    "        scores_0.append(final_results[f\"comments_number_0\"][f\"option_id_{i}\"][instance_id])\n",
    "        scores_1_low = []\n",
    "        scores_2_low = []\n",
    "        scores_3_low = []\n",
    "        scores_4_low = []\n",
    "        for j in range(len(list(permutation1(list(range(4)), 1)))):\n",
    "            scores_1_low.append(final_results[f\"comments_number_1\"][f\"option_id_{i}\"][f\"comments_order_{j}\"][instance_id])\n",
    "        for j in range(len(list(permutation1(list(range(4)), 2)))):\n",
    "            scores_2_low.append(final_results[f\"comments_number_2\"][f\"option_id_{i}\"][f\"comments_order_{j}\"][instance_id])\n",
    "        for j in range(len(list(permutation1(list(range(4)), 3)))):\n",
    "            scores_3_low.append(final_results[f\"comments_number_3\"][f\"option_id_{i}\"][f\"comments_order_{j}\"][instance_id])\n",
    "        for j in range(len(list(permutation1(list(range(4)), 4)))):\n",
    "            scores_4_low.append(final_results[f\"comments_number_4\"][f\"option_id_{i}\"][f\"comments_order_{j}\"][instance_id])\n",
    "        scores_1.append(scores_1_low)\n",
    "        scores_2.append(scores_2_low)\n",
    "        scores_3.append(scores_3_low)\n",
    "        scores_4.append(scores_4_low)\n",
    "    realldayufour.append([scores_0, scores_1, scores_2, scores_3, scores_4])\n",
    "\n",
    "\n",
    "dictkeys = [\"scores adding zero\",\"scores adding one\",\"scores adding two\",\"scores adding three\",\"scores adding four\"]\n",
    "if if_explicit:\n",
    "    savedir = \"MJD_Llama3_explicit_explanations.json\"\n",
    "else:\n",
    "    savedir = \"MJD_Llama3_explanations.json\"\n",
    "with open(savedir,\"w\") as f:\n",
    "    for line in realldayufour:\n",
    "        json.dump(dict(zip(dictkeys,line)),f)\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
